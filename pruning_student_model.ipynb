{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMqyaXvbcHYYTZwonQbjbKC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9a7586077ac1491ebcae532b1bc24958":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8a21ad1ed0240fbba7619f9939274bb","IPY_MODEL_d1af91ae2f9142fbba3c5f41aada1882","IPY_MODEL_6091deb87ccd4bbab2980d58c2c5b4d1"],"layout":"IPY_MODEL_0f2916bb07b548c0946f19bfeb4aa8b8"}},"f8a21ad1ed0240fbba7619f9939274bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea43c390ce3e4907a01b556a0fec2c0c","placeholder":"‚Äã","style":"IPY_MODEL_05e6dbdabcdf4adb95d31a3401fbe4b9","value":"Map:‚Äá100%"}},"d1af91ae2f9142fbba3c5f41aada1882":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dca302f7a8674d56a11b11725a4f0686","max":51695,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db712f1f4aa14836b6cd6d910c42e410","value":51695}},"6091deb87ccd4bbab2980d58c2c5b4d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_414cba7ed9f4468b925d5798082e3c5c","placeholder":"‚Äã","style":"IPY_MODEL_134bb6e7bb3646fc940112af59bba501","value":"‚Äá51695/51695‚Äá[01:46&lt;00:00,‚Äá993.15‚Äáexamples/s]"}},"0f2916bb07b548c0946f19bfeb4aa8b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea43c390ce3e4907a01b556a0fec2c0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05e6dbdabcdf4adb95d31a3401fbe4b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dca302f7a8674d56a11b11725a4f0686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db712f1f4aa14836b6cd6d910c42e410":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"414cba7ed9f4468b925d5798082e3c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"134bb6e7bb3646fc940112af59bba501":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# The rest of the code needs this package update\n","\n","!pip install datasets==4.0.0\n","\n","import datasets\n","print(datasets.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZZYLZLQxa3TF","executionInfo":{"status":"ok","timestamp":1752622146514,"user_tz":240,"elapsed":10359,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"31df2c87-a346-4380-a342-ddc63204d279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==4.0.0\n","  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (0.70.15)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (0.33.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==4.0.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==4.0.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==4.0.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==4.0.0) (2025.7.9)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n","Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fsspec, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.14.4\n","    Uninstalling datasets-2.14.4:\n","      Successfully uninstalled datasets-2.14.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-4.0.0 fsspec-2025.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["datasets","fsspec"]},"id":"2e588fbf3e034b32a48c0ab7776518f4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2.14.4\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-ZWnQdsUaZE","executionInfo":{"status":"ok","timestamp":1752622159343,"user_tz":240,"elapsed":647,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"1931d174-a4c6-411b-951d-3d94063f8897"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WaZGhJnyT_BL","executionInfo":{"status":"ok","timestamp":1752622179235,"user_tz":240,"elapsed":17810,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"8fc2a345-4b05-4b4a-ff22-ac3c122f9bbd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-1): 2 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=128, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=128, out_features=128, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":2}],"source":["from transformers import AutoModelForSequenceClassification\n","import torch\n","import os\n","\n","# Load fine-tuned BERT-tiny (distilled)\n","model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Postdoc/results/student/tiny-v2/checkpoint-epoch6\")\n","model.eval()"]},{"cell_type":"code","source":["# Display layers to prune\n","\n","for layer_idx, layer in enumerate(model.bert.encoder.layer):\n","    total_heads = layer.attention.self.num_attention_heads\n","    print(f\"Layer {layer_idx}: {total_heads} attention heads\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Nr5hfSTU6ds","executionInfo":{"status":"ok","timestamp":1752622182105,"user_tz":240,"elapsed":7,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"1b0214b3-1408-4da1-e835-74b60f8cc342"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer 0: 2 attention heads\n","Layer 1: 2 attention heads\n"]}]},{"cell_type":"code","source":["# Choose heads to prune manually\n","heads_to_prune = {\n","    0: [1],  # remove head 1 from layer 0\n","    1: [0]   # remove head 0 from layer 1\n","}\n","\n","# Apply head pruning\n","model.bert.prune_heads(heads_to_prune)\n","\n","# Save the pruned model\n","save_path = \"/content/drive/MyDrive/Colab Notebooks/Postdoc/results/student/tiny-v2/checkpoint-epoch6-pruned\"\n","model.save_pretrained(save_path)"],"metadata":{"id":"TW9qZIW0U8A3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Displying pruned layers\n","for layer_idx, layer in enumerate(model.bert.encoder.layer):\n","    total_heads = layer.attention.self.num_attention_heads\n","    print(f\"Layer {layer_idx}: {total_heads} attention heads\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pQVKs8OU_9F","executionInfo":{"status":"ok","timestamp":1752622188830,"user_tz":240,"elapsed":11,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"050aa30a-0c9a-43f5-a2ab-f88e95182972"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer 0: 1 attention heads\n","Layer 1: 1 attention heads\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset\n","\n","# Load and prepare dataset\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Postdoc/cleaned_stripped_mimic_notes.csv\")\n","print(df.shape)\n","\n","dataset = Dataset.from_pandas(df[[\"clean_relevant_note_truncate\", \"label\"]])\n","\n","# Split data into train and temp\n","temp_split = dataset.train_test_split(test_size=0.3, seed=42)\n","train_dataset = temp_split[\"train\"]\n","temp_dataset = temp_split[\"test\"]\n","\n","# Then split temp into val and test\n","val_test_split = temp_dataset.train_test_split(test_size=0.5, seed=42)\n","val_dataset = val_test_split[\"train\"]\n","test_dataset = val_test_split[\"test\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZO7IqTr3VIrw","executionInfo":{"status":"ok","timestamp":1752622193655,"user_tz":240,"elapsed":2267,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"7337a355-ff0d-42c5-ad1c-54352c495149"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(51695, 4)\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n","from transformers import AutoTokenizer\n","from torch.utils.data import DataLoader\n","\n","# Function to evaluate model on test set\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def evaluate_model_on_test_set_raw(model, test_dataset, tokenizer_name=\"gaunernst/bert-tiny-uncased\", batch_size=8):\n","    # Load tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n","\n","    # Create DataLoader that tokenizes on-the-fly\n","    def collate_fn(batch):\n","        texts = [x[\"clean_relevant_note_truncate\"] for x in batch]\n","        labels = torch.tensor([x[\"label\"] for x in batch])\n","        encodings = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n","        return encodings, labels\n","\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    # Move model to device\n","    model.eval()\n","    model.to(device)\n","\n","    all_logits = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n","            inputs, labels = batch\n","            inputs = {k: v.to(device) for k, v in inputs.items()}\n","            labels = labels.to(device)\n","\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","\n","            all_logits.append(logits.cpu())\n","            all_labels.append(labels.cpu())\n","\n","    # Concatenate results\n","    logits = torch.cat(all_logits, dim=0)\n","    labels = torch.cat(all_labels, dim=0)\n","    probs = torch.nn.functional.softmax(logits, dim=1)\n","    preds = torch.argmax(probs, dim=1).numpy()\n","\n","    # Compute metrics\n","    labels_np = labels.numpy()\n","    acc = accuracy_score(labels_np, preds)\n","    prec = precision_score(labels_np, preds)\n","    rec = recall_score(labels_np, preds)\n","    f1 = f1_score(labels_np, preds)\n","    auc = roc_auc_score(labels_np, probs[:, 1].numpy())\n","    cm = confusion_matrix(labels_np, preds)\n","\n","    # Display results\n","    print(\"üîç Test Set Evaluation:\")\n","    print(f\"Accuracy:  {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall:    {rec:.4f}\")\n","    print(f\"F1 Score:  {f1:.4f}\")\n","    print(f\"AUROC:     {auc:.4f}\")\n","    print(\"\\nConfusion Matrix:\")\n","    print(cm)\n","\n","    print(\"\\nDetailed Classification Report:\")\n","    print(classification_report(labels_np, preds, digits=4))\n","\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": prec,\n","        \"recall\": rec,\n","        \"f1\": f1,\n","        \"auroc\": auc,\n","        \"confusion_matrix\": cm\n","    }\n"],"metadata":{"id":"38iICnxSVJj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate pruned model on test set before retraining\n","\n","print(\"Pruned model:\")\n","results = evaluate_model_on_test_set_raw(model, test_dataset, tokenizer_name=\"gaunernst/bert-tiny-uncased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnNzwJ7DVPak","executionInfo":{"status":"ok","timestamp":1752622220199,"user_tz":240,"elapsed":21055,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"89d9a57c-3ec3-40ab-d921-7f76f382b2bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pruned model:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 970/970 [00:19<00:00, 49.51it/s]"]},{"output_type":"stream","name":"stdout","text":["üîç Test Set Evaluation:\n","Accuracy:  0.7474\n","Precision: 0.5872\n","Recall:    0.6071\n","F1 Score:  0.5970\n","AUROC:     0.7836\n","\n","Confusion Matrix:\n","[[4345 1020]\n"," [ 939 1451]]\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.8223    0.8099    0.8160      5365\n","           1     0.5872    0.6071    0.5970      2390\n","\n","    accuracy                         0.7474      7755\n","   macro avg     0.7048    0.7085    0.7065      7755\n","weighted avg     0.7498    0.7474    0.7485      7755\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","# Arguments for retraining\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Colab Notebooks/Postdoc/results/student/pruned-tiny/v1\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    logging_dir=\"/content/drive/MyDrive/Colab Notebooks/Postdoc/logs/student/pruned-tiny/v1\",\n","    logging_steps=50,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\"\n",")"],"metadata":{"id":"PCvl6E9LX9LU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","# Custom class to give label = 0 or 1 different weights in the cross entropy loss function, to account for class imbalance\n","class WeightedLossTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.get(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","\n","        # Setting the weights here\n","        weights = torch.tensor([0.72, 1.60]).to(logits.device)\n","        loss_fct = torch.nn.CrossEntropyLoss(weight=weights)\n","        loss = loss_fct(logits, labels)\n","        return (loss, outputs) if return_outputs else loss\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gaunernst/bert-tiny-uncased\")"],"metadata":{"id":"nNBNyaQNYncT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","!pip install evaluate\n","import evaluate\n","\n","# Metrics to compute\n","\n","accuracy = evaluate.load(\"accuracy\")\n","f1 = evaluate.load(\"f1\")\n","precision = evaluate.load(\"precision\")\n","recall = evaluate.load(\"recall\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","    return {\n","        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n","        \"f1\": f1.compute(predictions=preds, references=labels)[\"f1\"],\n","        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n","        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUB2argSZb9F","executionInfo":{"status":"ok","timestamp":1752622253587,"user_tz":240,"elapsed":11337,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"1e0c9911-38ac-42c4-a30c-d6c99ee0f679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.9)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"]}]},{"cell_type":"code","source":["# Tokenize all examples\n","\n","def tokenize_batch(example):\n","    return tokenizer(\n","        example[\"clean_relevant_note_truncate\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=512\n","    )\n","\n","tokenized_dataset = dataset.map(tokenize_batch, batched=True)\n","\n","tokenized_dataset.set_format(\n","    type='torch',\n","    columns=['input_ids', 'attention_mask', 'label']\n",")\n","\n","# Split data into train and temp\n","temp_split = tokenized_dataset.train_test_split(test_size=0.3, seed=42)\n","train_dataset = temp_split[\"train\"]\n","temp_dataset = temp_split[\"test\"]\n","\n","# Then split temp into val and test\n","val_test_split = temp_dataset.train_test_split(test_size=0.5, seed=42)\n","val_dataset = val_test_split[\"train\"]\n","test_dataset = val_test_split[\"test\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["9a7586077ac1491ebcae532b1bc24958","f8a21ad1ed0240fbba7619f9939274bb","d1af91ae2f9142fbba3c5f41aada1882","6091deb87ccd4bbab2980d58c2c5b4d1","0f2916bb07b548c0946f19bfeb4aa8b8","ea43c390ce3e4907a01b556a0fec2c0c","05e6dbdabcdf4adb95d31a3401fbe4b9","dca302f7a8674d56a11b11725a4f0686","db712f1f4aa14836b6cd6d910c42e410","414cba7ed9f4468b925d5798082e3c5c","134bb6e7bb3646fc940112af59bba501"]},"id":"jvPbzj9qbZrp","executionInfo":{"status":"ok","timestamp":1752622386948,"user_tz":240,"elapsed":106756,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"dc3e95b8-7a89-4bf0-eb2c-3da34672905f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/51695 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7586077ac1491ebcae532b1bc24958"}},"metadata":{}}]},{"cell_type":"code","source":["trainer = WeightedLossTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HeTAFR9DZEJ4","executionInfo":{"status":"ok","timestamp":1752622391961,"user_tz":240,"elapsed":2835,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"d6e9ba51-3840-4e57-fd91-4b2e622585de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-13-1845219473.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedLossTrainer.__init__`. Use `processing_class` instead.\n","  trainer = WeightedLossTrainer(\n"]}]},{"cell_type":"code","source":["# Train model on 5 epochs\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"iOX4NE4cZpxn","executionInfo":{"status":"ok","timestamp":1752622858560,"user_tz":240,"elapsed":464046,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"a31280f6-9378-4ce0-c86f-d27129b273a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlili-zeng\u001b[0m (\u001b[33mlili-zeng-mcgill-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250715_233315-cb71ao20</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/lili-zeng-mcgill-university/huggingface/runs/cb71ao20' target=\"_blank\">/content/drive/MyDrive/Colab Notebooks/Postdoc/results/student/pruned-tiny/v1</a></strong> to <a href='https://wandb.ai/lili-zeng-mcgill-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/lili-zeng-mcgill-university/huggingface' target=\"_blank\">https://wandb.ai/lili-zeng-mcgill-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/lili-zeng-mcgill-university/huggingface/runs/cb71ao20' target=\"_blank\">https://wandb.ai/lili-zeng-mcgill-university/huggingface/runs/cb71ao20</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='22620' max='22620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [22620/22620 07:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.473300</td>\n","      <td>0.557937</td>\n","      <td>0.759479</td>\n","      <td>0.626028</td>\n","      <td>0.652047</td>\n","      <td>0.602005</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.414200</td>\n","      <td>0.574647</td>\n","      <td>0.752515</td>\n","      <td>0.624829</td>\n","      <td>0.667502</td>\n","      <td>0.587284</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.401600</td>\n","      <td>0.573316</td>\n","      <td>0.758834</td>\n","      <td>0.621304</td>\n","      <td>0.640769</td>\n","      <td>0.602987</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.450700</td>\n","      <td>0.600091</td>\n","      <td>0.764638</td>\n","      <td>0.625487</td>\n","      <td>0.636591</td>\n","      <td>0.614764</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.409200</td>\n","      <td>0.616230</td>\n","      <td>0.765025</td>\n","      <td>0.622462</td>\n","      <td>0.627402</td>\n","      <td>0.617599</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=22620, training_loss=0.46328381463345125, metrics={'train_runtime': 464.0467, 'train_samples_per_second': 389.896, 'train_steps_per_second': 48.745, 'total_flos': 193229766144000.0, 'train_loss': 0.46328381463345125, 'epoch': 5.0})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Save model and tokenizer to a folder\n","trainer.save_model(\"/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1\")           # saves model weights + config\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1\")    # saves tokenizer files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Kv1VOOhc1NT","executionInfo":{"status":"ok","timestamp":1752622863306,"user_tz":240,"elapsed":147,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"8ad4b2eb-7f1e-4f8d-b252-bb74111fc618"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1/vocab.txt',\n"," '/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1/added_tokens.json',\n"," '/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1/tokenizer.json')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n","import torch\n","\n","# Function to evaluate the model on the test set\n","def evaluate_model_on_test_set(trainer, test_dataset):\n","    # Ensure test dataset is in torch format\n","    test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","    # Run model predictions\n","    predictions = trainer.predict(test_dataset)\n","    logits = predictions.predictions\n","    labels = predictions.label_ids\n","    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=1)\n","    preds = torch.argmax(probs, axis=1).numpy()\n","\n","    # Compute metrics\n","    acc = accuracy_score(labels, preds)\n","    prec = precision_score(labels, preds)\n","    rec = recall_score(labels, preds)\n","    f1 = f1_score(labels, preds)\n","    auc = roc_auc_score(labels, probs[:, 1])\n","    cm = confusion_matrix(labels, preds)\n","\n","    # Display results\n","    print(\"üîç Test Set Evaluation:\")\n","    print(f\"Accuracy:  {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall:    {rec:.4f}\")\n","    print(f\"F1 Score:  {f1:.4f}\")\n","    print(f\"AUROC:     {auc:.4f}\")\n","    print(\"\\nConfusion Matrix:\")\n","    print(cm)\n","\n","    print(\"\\nDetailed Classification Report:\")\n","    print(classification_report(labels, preds, digits=4))\n","\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": prec,\n","        \"recall\": rec,\n","        \"f1\": f1,\n","        \"auroc\": auc,\n","        \"confusion_matrix\": cm\n","    }"],"metadata":{"id":"U1jFCMBDcRul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate model after retraining.\n","\n","print(\"Pruned model retrained:\")\n","results = evaluate_model_on_test_set(trainer, test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"pbD_8B8VZhgg","executionInfo":{"status":"ok","timestamp":1752622890897,"user_tz":240,"elapsed":6307,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"8ff9e098-e078-4068-ebf5-f42a6b1eda0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pruned model retrained:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üîç Test Set Evaluation:\n","Accuracy:  0.7631\n","Precision: 0.6085\n","Recall:    0.6490\n","F1 Score:  0.6281\n","AUROC:     0.8106\n","\n","Confusion Matrix:\n","[[4367  998]\n"," [ 839 1551]]\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.8388    0.8140    0.8262      5365\n","           1     0.6085    0.6490    0.6281      2390\n","\n","    accuracy                         0.7631      7755\n","   macro avg     0.7237    0.7315    0.7271      7755\n","weighted avg     0.7678    0.7631    0.7652      7755\n","\n"]}]}]}