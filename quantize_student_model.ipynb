{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeRhKNElWa3CiEhZy8Xgpx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5af9142a7008424fa0c402a3fcad35a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90c05f2e8ca14104ac0da6ede6333d07","IPY_MODEL_78ef4c28845c4ba79c82315a7209c199","IPY_MODEL_8d54d16ae7e04dc2a58aa65670d1b14f"],"layout":"IPY_MODEL_fb67dcb94c3a4492b1af042393015dc8"}},"90c05f2e8ca14104ac0da6ede6333d07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b20bddf383dd4a2b9df348efac4046aa","placeholder":"​","style":"IPY_MODEL_1298d72ccd224366ac778ac5915436b0","value":"tokenizer_config.json: 100%"}},"78ef4c28845c4ba79c82315a7209c199":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3faf0270e5b24c00b934bf56150cb269","max":32,"min":0,"orientation":"horizontal","style":"IPY_MODEL_191de26f10964640a67da49cfaacefee","value":32}},"8d54d16ae7e04dc2a58aa65670d1b14f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f071c7bba0d4644a848b8fde024b550","placeholder":"​","style":"IPY_MODEL_5816e2e4f87b475cb01894de3a81ebfc","value":" 32.0/32.0 [00:00&lt;00:00, 1.60kB/s]"}},"fb67dcb94c3a4492b1af042393015dc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b20bddf383dd4a2b9df348efac4046aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1298d72ccd224366ac778ac5915436b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3faf0270e5b24c00b934bf56150cb269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"191de26f10964640a67da49cfaacefee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f071c7bba0d4644a848b8fde024b550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5816e2e4f87b475cb01894de3a81ebfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eae45f5b80214a4597afd087902ae0a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd067a5f94f2446e80c6b21e0b13de89","IPY_MODEL_dd0e92b24495446bb9cf77c534cd9fb1","IPY_MODEL_7d630c72ba604ee7995d6dfec1325c58"],"layout":"IPY_MODEL_422e58bbb0b8447ebcb64e5c1efd1c6a"}},"dd067a5f94f2446e80c6b21e0b13de89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3f13485276c4602a02f4baa9e8a3f79","placeholder":"​","style":"IPY_MODEL_a6aada38961e493390f28ea97b562f4f","value":"config.json: 100%"}},"dd0e92b24495446bb9cf77c534cd9fb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_763d2e523f5e4cddaea3baf31ddcaf14","max":528,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa1b3c32676b4afab4ff5610430f82e8","value":528}},"7d630c72ba604ee7995d6dfec1325c58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f36567c7e5074603a7b0302d6d1b0ddb","placeholder":"​","style":"IPY_MODEL_72b2ce6279fa4a60accc0a15c8217bb4","value":" 528/528 [00:00&lt;00:00, 13.2kB/s]"}},"422e58bbb0b8447ebcb64e5c1efd1c6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3f13485276c4602a02f4baa9e8a3f79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6aada38961e493390f28ea97b562f4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"763d2e523f5e4cddaea3baf31ddcaf14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa1b3c32676b4afab4ff5610430f82e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f36567c7e5074603a7b0302d6d1b0ddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72b2ce6279fa4a60accc0a15c8217bb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4770c6cd55ff414bbeadd64f4810b961":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_342abbf414144e6e813a40cfbc81b629","IPY_MODEL_0fedd7e4d63645c4bbe5e2b42334069a","IPY_MODEL_6b114ff1d4b04324b476bf297ceac198"],"layout":"IPY_MODEL_6f09710eb89f4e12ba789d507c9323d2"}},"342abbf414144e6e813a40cfbc81b629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d504ba867aa4ea58856981687842b19","placeholder":"​","style":"IPY_MODEL_2e958dc8fc394c95b5b6f33676846873","value":"vocab.txt: "}},"0fedd7e4d63645c4bbe5e2b42334069a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9940de1792e4d6e800b0278943d80a1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d9b59e0d5bf41a8b5fd88e2af6f604a","value":1}},"6b114ff1d4b04324b476bf297ceac198":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd86e48c7864b538b2f5b4f69bc6486","placeholder":"​","style":"IPY_MODEL_e76d6fa6a752471598a9e9247ab98187","value":" 232k/? [00:00&lt;00:00, 6.97MB/s]"}},"6f09710eb89f4e12ba789d507c9323d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d504ba867aa4ea58856981687842b19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e958dc8fc394c95b5b6f33676846873":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9940de1792e4d6e800b0278943d80a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3d9b59e0d5bf41a8b5fd88e2af6f604a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bd86e48c7864b538b2f5b4f69bc6486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e76d6fa6a752471598a9e9247ab98187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 1. Quantize the distilled student model"],"metadata":{"id":"ovmCPcQJoujr"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2KBqaW0AN6K","executionInfo":{"status":"ok","timestamp":1752696606945,"user_tz":240,"elapsed":18615,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"29b45d4b-c1ed-425e-e177-835ef4bcf6d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForSequenceClassification\n","\n","# Load the distilled student model\n","\n","student_model_path = \"/content/drive/MyDrive/Colab Notebooks/Postdoc/results/student/tiny-v2/checkpoint-epoch6\"\n","student_model_fp32 = AutoModelForSequenceClassification.from_pretrained(student_model_path)\n","student_model_fp32.eval()  # Always eval mode for quantization\n","\n","device = torch.device(\"cpu\")"],"metadata":{"id":"Q8iem7SQFFaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset\n","\n","# Prepare dataset\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Postdoc/cleaned_stripped_mimic_notes.csv\")\n","print(df.shape)\n","\n","dataset = Dataset.from_pandas(df[[\"clean_relevant_note_truncate\", \"label\"]])\n","\n","# Split data into train and temp\n","temp_split = dataset.train_test_split(test_size=0.3, seed=42)\n","train_dataset = temp_split[\"train\"]\n","temp_dataset = temp_split[\"test\"]\n","\n","# Then split temp into val and test\n","val_test_split = temp_dataset.train_test_split(test_size=0.5, seed=42)\n","val_dataset = val_test_split[\"train\"]\n","test_dataset = val_test_split[\"test\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bn7kHhCdAo4Q","executionInfo":{"status":"ok","timestamp":1752623275761,"user_tz":240,"elapsed":3324,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"3bb7fbbe-05d2-4321-da9c-babb82693dca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(51695, 4)\n"]}]},{"cell_type":"code","source":["# Quantize Linear (fully connected) layers\n","student_model_quantized = torch.quantization.quantize_dynamic(\n","    student_model_fp32,  # model\n","    {torch.nn.Linear},   # layers to quantize\n","    dtype=torch.qint8    # quantize to int8\n",")\n","\n","print(student_model_quantized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14KvigF5AdqW","executionInfo":{"status":"ok","timestamp":1752601178500,"user_tz":240,"elapsed":52,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"484b2d17-a4e1-4310-8eea-a669f9be2df8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-1): 2 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=128, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=128, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=128, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=128, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=128, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): DynamicQuantizedLinear(in_features=512, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): DynamicQuantizedLinear(in_features=128, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): DynamicQuantizedLinear(in_features=128, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")\n"]}]},{"cell_type":"code","source":["# Save quantized model\n","\n","quantized_model_path = student_model_path + \"-quantized/\"\n","torch.save(student_model_quantized.state_dict(), quantized_model_path + \"quantized_student_model.pt\")"],"metadata":{"id":"oRfPNGttAkQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n","\n","# Function to evaluate model on test set\n","\n","def evaluate_model_on_test_set_raw(model, test_dataset, tokenizer_name=\"gaunernst/bert-tiny-uncased\", batch_size=8):\n","    # Load tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n","\n","    # Create DataLoader that tokenizes on-the-fly\n","    def collate_fn(batch):\n","        texts = [x[\"clean_relevant_note_truncate\"] for x in batch]\n","        labels = torch.tensor([x[\"label\"] for x in batch])\n","        encodings = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n","        return encodings, labels\n","\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    # Move model to device\n","    model.eval()\n","    model.to(device)\n","\n","    all_logits = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n","            inputs, labels = batch\n","            inputs = {k: v.to(device) for k, v in inputs.items()}\n","            labels = labels.to(device)\n","\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","\n","            all_logits.append(logits.cpu())\n","            all_labels.append(labels.cpu())\n","\n","    # Concatenate results\n","    logits = torch.cat(all_logits, dim=0)\n","    labels = torch.cat(all_labels, dim=0)\n","    probs = torch.nn.functional.softmax(logits, dim=1)\n","    preds = torch.argmax(probs, dim=1).numpy()\n","\n","    # Compute metrics\n","    labels_np = labels.numpy()\n","    acc = accuracy_score(labels_np, preds)\n","    prec = precision_score(labels_np, preds)\n","    rec = recall_score(labels_np, preds)\n","    f1 = f1_score(labels_np, preds)\n","    auc = roc_auc_score(labels_np, probs[:, 1].numpy())\n","    cm = confusion_matrix(labels_np, preds)\n","\n","    # Display results\n","    print(\"🔍 Test Set Evaluation:\")\n","    print(f\"Accuracy:  {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall:    {rec:.4f}\")\n","    print(f\"F1 Score:  {f1:.4f}\")\n","    print(f\"AUROC:     {auc:.4f}\")\n","    print(\"\\nConfusion Matrix:\")\n","    print(cm)\n","\n","    print(\"\\nDetailed Classification Report:\")\n","    print(classification_report(labels_np, preds, digits=4))\n","\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": prec,\n","        \"recall\": rec,\n","        \"f1\": f1,\n","        \"auroc\": auc,\n","        \"confusion_matrix\": cm\n","    }\n"],"metadata":{"id":"aBrbFDo-A8IG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from torch.utils.data import DataLoader\n","\n","# Load tokenizer (same as before)\n","tokenizer = AutoTokenizer.from_pretrained(\"gaunernst/bert-tiny-uncased\")\n","\n","# Load quantized model\n","student_model_quantized.eval()\n","student_model_quantized.to(\"cpu\")  # Quantized models should run on CPU\n","\n","# Evaluate quantized model performance\n","results = evaluate_model_on_test_set_raw(\n","    model=student_model_quantized,\n","    test_dataset=test_dataset,\n","    tokenizer_name=\"gaunernst/bert-tiny-uncased\",\n",")\n","\n","print(\"📊 Quantized model performance:\")\n","for k, v in results.items():\n","    print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-JSEnNcAwrR","executionInfo":{"status":"ok","timestamp":1752601749010,"user_tz":240,"elapsed":94433,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"3c695bfc-22ea-4c5f-cfeb-db35a58e94e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 970/970 [01:32<00:00, 10.47it/s]"]},{"output_type":"stream","name":"stdout","text":["🔍 Test Set Evaluation:\n","Accuracy:  0.7812\n","Precision: 0.6243\n","Recall:    0.7280\n","F1 Score:  0.6722\n","AUROC:     0.8402\n","\n","Confusion Matrix:\n","[[4318 1047]\n"," [ 650 1740]]\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.8692    0.8048    0.8358      5365\n","           1     0.6243    0.7280    0.6722      2390\n","\n","    accuracy                         0.7812      7755\n","   macro avg     0.7467    0.7664    0.7540      7755\n","weighted avg     0.7937    0.7812    0.7854      7755\n","\n","📊 Quantized model performance:\n","accuracy: 0.7812\n","precision: 0.6243\n","recall: 0.7280\n","f1: 0.6722\n","auroc: 0.8402\n","confusion_matrix: [[4318 1047]\n"," [ 650 1740]]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# 2. Quantize the pruned student model"],"metadata":{"id":"jV30nidyo1F8"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForSequenceClassification\n","\n","# Load the pruned student model\n","\n","student_model_path = \"/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/v1\"\n","student_model_fp32 = AutoModelForSequenceClassification.from_pretrained(student_model_path)\n","student_model_fp32.eval()  # Always eval mode for quantization\n","\n","device = torch.device(\"cpu\")"],"metadata":{"id":"vjDFJQNGfAQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Quantize Linear (fully connected) layers\n","student_model_quantized = torch.quantization.quantize_dynamic(\n","    student_model_fp32,  # model\n","    {torch.nn.Linear},   # layers to quantize\n","    dtype=torch.qint8    # quantize to int8\n",")\n","\n","print(student_model_quantized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxq60iGufHe6","executionInfo":{"status":"ok","timestamp":1752623288477,"user_tz":240,"elapsed":413,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"970b55d1-84e1-414b-b8c3-4d74eb5f3c5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-1): 2 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=128, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=128, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=128, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=64, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=128, out_features=512, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): DynamicQuantizedLinear(in_features=512, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): DynamicQuantizedLinear(in_features=128, out_features=128, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): DynamicQuantizedLinear(in_features=128, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from torch.utils.data import DataLoader\n","\n","# Load tokenizer (same as before)\n","tokenizer = AutoTokenizer.from_pretrained(\"gaunernst/bert-tiny-uncased\")\n","\n","# Load quantized model\n","student_model_quantized.eval()\n","student_model_quantized.to(\"cpu\")  # Quantized models should run on CPU\n","\n","# Evaluate quantized model performance\n","results = evaluate_model_on_test_set_raw(\n","    model=student_model_quantized,\n","    test_dataset=test_dataset,\n","    tokenizer_name=\"gaunernst/bert-tiny-uncased\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633,"referenced_widgets":["5af9142a7008424fa0c402a3fcad35a4","90c05f2e8ca14104ac0da6ede6333d07","78ef4c28845c4ba79c82315a7209c199","8d54d16ae7e04dc2a58aa65670d1b14f","fb67dcb94c3a4492b1af042393015dc8","b20bddf383dd4a2b9df348efac4046aa","1298d72ccd224366ac778ac5915436b0","3faf0270e5b24c00b934bf56150cb269","191de26f10964640a67da49cfaacefee","8f071c7bba0d4644a848b8fde024b550","5816e2e4f87b475cb01894de3a81ebfc","eae45f5b80214a4597afd087902ae0a1","dd067a5f94f2446e80c6b21e0b13de89","dd0e92b24495446bb9cf77c534cd9fb1","7d630c72ba604ee7995d6dfec1325c58","422e58bbb0b8447ebcb64e5c1efd1c6a","e3f13485276c4602a02f4baa9e8a3f79","a6aada38961e493390f28ea97b562f4f","763d2e523f5e4cddaea3baf31ddcaf14","fa1b3c32676b4afab4ff5610430f82e8","f36567c7e5074603a7b0302d6d1b0ddb","72b2ce6279fa4a60accc0a15c8217bb4","4770c6cd55ff414bbeadd64f4810b961","342abbf414144e6e813a40cfbc81b629","0fedd7e4d63645c4bbe5e2b42334069a","6b114ff1d4b04324b476bf297ceac198","6f09710eb89f4e12ba789d507c9323d2","2d504ba867aa4ea58856981687842b19","2e958dc8fc394c95b5b6f33676846873","c9940de1792e4d6e800b0278943d80a1","3d9b59e0d5bf41a8b5fd88e2af6f604a","5bd86e48c7864b538b2f5b4f69bc6486","e76d6fa6a752471598a9e9247ab98187"]},"id":"WPzjS-zKfY3H","executionInfo":{"status":"ok","timestamp":1752623416147,"user_tz":240,"elapsed":92447,"user":{"displayName":"Lili Zeng","userId":"05905552918070490667"}},"outputId":"65c1facb-37d7-4ee8-c932-896e050089dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/32.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af9142a7008424fa0c402a3fcad35a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae45f5b80214a4597afd087902ae0a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4770c6cd55ff414bbeadd64f4810b961"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 970/970 [01:31<00:00, 10.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["🔍 Test Set Evaluation:\n","Accuracy:  0.7683\n","Precision: 0.6216\n","Recall:    0.6343\n","F1 Score:  0.6279\n","AUROC:     0.8108\n","\n","Confusion Matrix:\n","[[4442  923]\n"," [ 874 1516]]\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.8356    0.8280    0.8318      5365\n","           1     0.6216    0.6343    0.6279      2390\n","\n","    accuracy                         0.7683      7755\n","   macro avg     0.7286    0.7311    0.7298      7755\n","weighted avg     0.7696    0.7683    0.7689      7755\n","\n"]}]},{"cell_type":"code","source":["# Save quantized pruned model\n","torch.save(student_model_quantized.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/Postdoc/BERT-tiny-student-model-pruned/quantized-v1/quantized-pruned_model.pt\")"],"metadata":{"id":"oelLzQxpfccN"},"execution_count":null,"outputs":[]}]}